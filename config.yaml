conv_subsample_lengths: [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1], #15 layers
conv_filter_length: 16,
conv_num_filters_start: 64,
conv_init: "he_normal",
conv_activation: "relu",
conv_dropout: 0.2,
conv_num_skip: 2,
conv_increase_channels_at: 4,
conv_pool_at: 2,
num_categories:1,

input_shape:[2048,12],

l2_kern_weight: 0.0001,
l2_bias_weight: 0.0001,

hidden_layers: 1,
hidden_size:1024,

num_middle_layers: 15,
num_convs_per_layer: 1,

learning_rate: 1e-3,
batch_size": 64,
